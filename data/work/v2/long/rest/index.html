<?xml version="1.0"?>
<response><item key="0"><uuid><value>19bf766e-fc8a-4d20-abe2-f4d7786f3931</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2020-11-30T10:17:37+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>446b9999-8a78-45c8-b558-c875d4aee362</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></uid><title><value>  SEER: Simulative Emotional Expression Robot</value></title><created><value>2020-09-18T13:43:20+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2020-11-30T10:17:37+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/seer-simulative-emotional-expression-robot</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>75933635-4f39-4c66-a518-b5e0b89afca2</target_uuid></field_author_name><field_characters><target_type>node</target_type><target_uuid>9919d27c-cf38-44f5-86ec-fdfe28565e91</target_uuid></field_characters><field_country><value>JP</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>ff3d9bb7-c35d-4f71-ac9e-46850b9be966</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>94cfbf5e-c66e-467a-9971-6af2a2cb2843</target_uuid></field_media_asset><field_multi_image/><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>dd951d1c-96fd-4892-8ce6-0de1ad9f5d7a</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>a73953c0-6ccf-499a-9d52-f9e485fcc469</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>c4c1372a-9ab3-46d9-8dcc-bbb8d551cee6</target_uuid></field_technologies_referenced><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>a46eb94c-b7bd-41bb-855e-55bba9920c6d</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>“SEER” is a humanoid robotic head developed as an artistic work by Takayuki Todo. It explores the significance of gaze and facial expression in the sphere of human-machine research.</p>

<p>Takayuki Todo is interested in how people establish an emotional relationship with humanoid robots. As the discipline of robotics has shown for years, a realistic similarity to the human form alone is not able to break down the distance between a human and a machine. The term “uncanny valley” refers to this very narrow but significant gap between what a person perceives as real and credible, and what they perceive as artificial and uncanny.<br />
For Todo, the central element that offers a way out of the “uncanny valley” is the gaze. For years he has been working on anthropomorphic figures that are made of entirely synthetic materials yet acquire a liveliness through their gaze. Created in 2018, Todo calls his “Simulative Emotional Expression Robot” “SEER” - evocative of a seeing being. Using a 3D printer, the artist produced a head made of several parts that was designed on a reduced scale and without any gender or ethnicity-specific features.<br />
The robot has a camera that perceives the human counterpart, focuses, and then reciprocates their gaze. “SEER” not only interacts with the viewer through eye contact, but also by nodding its head and moving its eyes, eyelids and eyebrows. The intensity of the movements increases as the person approaches “SEER”. The figure has a childlike physiognomy, its facial expressions and movements are comforting in their tenderness. “SEER” seems to have a life of its own in which it encounters us. It reflects the facial expressions of its counterpart, it generates movements as reproductions of existing ones, but does not produce any autonomous gestures.</p>

<p>Source: http://www.takayukitodo.com/<br />
(Script by Franziska Nori (the director of Frankfurter Kunstverein))</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>ce0404a8-1d5b-43ee-a1c3-7444adbcc285</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>ccb277b8-7291-4fa3-9b5e-ad4ce135623a</target_uuid></field_themes><field_url><uri>http://www.takayukitodo.com/</uri><title></title><options/></field_url><field_year><value>2018-01-01</value></field_year></item><item key="1"><uuid><value>af19a54a-551e-4d93-afba-ad3df6c626bc</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-11-08T14:24:57+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>446b9999-8a78-45c8-b558-c875d4aee362</target_uuid></revision_uid><revision_log><value>Both situations are approved by two people, so I am switching main entry to two people. This was discussed.</value></revision_log><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>7841d591-a1b7-42a1-8b43-52aab9548103</target_uuid></uid><title><value> Captain America: The Winter soldier </value></title><created><value>2020-11-03T14:10:44+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-11-08T14:24:57+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/captain-america-winter-soldier</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>103b5f56-9f4f-472e-af56-4b9ad075a083</target_uuid></field_author_name><field_characters><target_type>node</target_type><target_uuid>f1e4858f-39ad-4b26-a5eb-1dd107f36a5c</target_uuid></field_characters><field_characters><target_type>node</target_type><target_uuid>11bd8fc0-f091-43d5-93cd-735fda1ce785</target_uuid></field_characters><field_country><value>US</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>73655976-6c4b-4261-90b2-4f1d36081272</target_uuid></field_machine_vision_situation><field_machine_vision_situation><target_type>node</target_type><target_uuid>c530ccff-7f6b-4f62-805d-bc027cb240d4</target_uuid></field_machine_vision_situation><field_media_asset/><field_multi_image><target_type>media</target_type><target_uuid>28ff9968-1ff7-4738-b21f-6153085724d4</target_uuid></field_multi_image><field_notes><value>Changed biometrics to body scan because in the situation it is a body scan and that is missing. I left surveillance cameras as they probably are referenced in the movie even if not in the situations. The sentiment towards machine vision was defined as hostile, empowering and fun. However in the MV situations they are mostly helpful. This was left as a draft and it seams there is very few MV situations. I am not able to watch the movie so not sure if the sentiments are for the film or towards machine vision. Also there is way more characters connected to the work than used in the MV situations. (Linda)</value></field_notes><field_notes><value>After discussion I deleted the characters that are not </value></field_notes><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>8bfaa6d9-607e-4628-92df-bc08840bd8c7</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>0a42628e-925e-48b1-a8e8-7ecb7916df7a</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>1</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>0af6164e-59d5-444f-9232-e0188c36457f</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>6d5338f3-19b9-41c4-86e8-026bd76a39b0</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>791bba71-1937-4481-8f9c-a8b4be6a48fd</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>d7af7574-e004-45fd-8f20-0edf400bf9a3</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>b4c86e39-89b0-47b7-b4aa-b13a415c5054</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>e3906ce1-7dd4-4b76-98d2-e86add14977e</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>c75f40e5-3fb7-4d4b-84b8-dc9c1f650d9d</target_uuid></field_technologies_referenced><field_technologies_used/><field_textfield><value><![CDATA[<p>Two years after the Battle of New York, Captain America&nbsp;works in DC, for the espionage agency S.H.I.E.L.D under Director Nick Fury, while adjusting to contemporary society. Rogers and Agent Natasha are sent with S.H.I.E.L.D.'s strike&nbsp;team, led by Agent Rumlow, to free hostages aboard a S.H.I.E.L.D. vessel from pirates. Mid-mission, Rogers discovers the pirates has another agenda: to extract data from the ship's computers for the director. Rogers returns to S.H.I.E.L.D.'s headquarters, to confront Fury and is briefed about Project Insight: three machines&nbsp;linked to spy satellites, designed to preemptively eliminate threats. Unable to decrypt the data recovered by Romanoff, Fury becomes suspicious about Insight and asks senior S.H.I.E.L.D. official and Secretary of Internal Security Alexander Pierce&nbsp;to delay the project.</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>8581a668-2e39-40e0-a4f5-46dda9a54316</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>3f146c33-1e1b-4264-9786-2059cc130da3</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>e8dab263-5453-4aa9-a3bd-7f51e393d623</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>e6e09da9-caeb-4fd0-bd2f-ac24a2083283</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>30f6022b-5fcf-4e9c-a379-cdaf88e8bb97</target_uuid></field_themes><field_url/><field_year><value>2016-04-12</value></field_year></item><item key="2"><uuid><value>2ca1e37d-4d80-4873-84f3-abf2372bc9c2</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-09-14T09:29:29+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></uid><title><value> The Human Detector</value></title><created><value>2021-09-14T08:41:18+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-09-14T09:29:29+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/human-detector</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>1e007e71-290c-4b03-80f9-dd3b7bece9cf</target_uuid></field_author_name><field_characters/><field_country><value>CM</value></field_country><field_country><value>FR</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>213f7102-a6e1-4e78-b017-55b3ba69e5ea</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>7e5c0c0f-aa66-48a6-b59c-246964ffff57</target_uuid></field_media_asset><field_multi_image><target_type>media</target_type><target_uuid>9a8dde38-003a-4b6f-a1be-e02c3487d4c3</target_uuid></field_multi_image><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>460e8d77-8885-419b-ab02-4fa010a995a5</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>21789815-9286-4c11-bdb1-f9921745b2af</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ecb9076e-8a09-4ca1-a615-e81b701acab4</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>ff47ddec-81d9-47ff-96c0-71a470263e05</target_uuid></field_technologies_referenced><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>ff47ddec-81d9-47ff-96c0-71a470263e05</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>Based on the personal experience of discriminating facial detection models Iyo created a game in which the goal is to avoid to be detected:<br />
"facial detection algorithms were struggling to detect me, and the reason they were struggling to detect me is because I’m black. I had to be very creative to be detected so during the workshop" (1)<br />
&nbsp;</p>

<p>The Human Detector inverts the rules, it becomes a gain not to be detected:<br />
"By doing this, I recreated my own experience with ml4a and AI, but I inverted the rules so that I win every time.&nbsp;" (1)</p>

<p>By subverting the rules of the facial detection apparatus Iyo aims to question what biases are propagated by machine vision technologies such as facial recognition.</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>8581a668-2e39-40e0-a4f5-46dda9a54316</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>406d3729-ee22-48ba-b998-c2fcb6296eae</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>e8dab263-5453-4aa9-a3bd-7f51e393d623</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>3b1b7eb6-c30d-44f8-a322-9b92fa665541</target_uuid></field_themes><field_url><uri>https://iyo.io/</uri><title>Artist website</title><options/></field_url><field_url><uri>https://vimeo.com/347283293</uri><title>Vimeo Link</title><options/></field_url><field_year><value>2018-01-01</value></field_year></item><item key="3"><uuid><value>9f4622cb-5565-452d-9cbe-b1fff06823b9</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-03-26T15:15:43+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>e061791f-08b7-4180-87aa-627c81734443</target_uuid></uid><title><value> What the Robot Saw</value></title><created><value>2020-09-08T12:25:48+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-03-26T15:15:43+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/what-robot-saw</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>4395776a-3810-4a31-bdca-8cc94c53b798</target_uuid></field_author_name><field_characters/><field_country><value>US</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>96d833a6-2c8c-4db0-8b7e-4fa4e98f0156</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>bfe5ff88-c69c-49ce-9488-8a710fd6dcf8</target_uuid></field_media_asset><field_media_asset><target_type>media</target_type><target_uuid>00555f23-9d82-4f1e-bd57-7ae056ddfbc4</target_uuid></field_media_asset><field_multi_image><target_type>media</target_type><target_uuid>66635fe6-61ed-4fca-9bbe-44b1332a46c6</target_uuid></field_multi_image><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>03a9e9a2-0bc5-4596-8f67-a11211e0ebef</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ff48d007-ea6a-441b-b998-138dab64c246</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>e62fa1ca-3a49-45e7-bcb6-33a1ddc32723</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>ff47ddec-81d9-47ff-96c0-71a470263e05</target_uuid></field_technologies_referenced><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>a46eb94c-b7bd-41bb-855e-55bba9920c6d</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>b3adc0bc-b002-4235-87d1-97199c3cafdd</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p><em>Does the Internet suck? Or do just the parts we get to see suck?</em></p>

<p>Who doesn’t get seen on the internet? In the new world order of robots and talking heads, a reality exists that’s part life, part cinema, and part algorithm. But as the robot curators silently curate, an alternate reality also emerges, starring the humans who win at losing the losing social media game. A secret cinematic world, seen only by robots.&nbsp;</p>

<p><strong>‘What the Robot Saw’</strong>&nbsp;is a perpetually-generated robot documentary live stream and durational online performance and&nbsp;&nbsp;<a href="https://www.youtube.com/user/uebervideos/videos">archive</a>. It’s a Sunday drive through the awkward intersections of performance, surveillance, voyeurism, and robots — in the age of the talking head. The Robot uses contrarian ranking algorithms to curate some of the least attention-grabbing new videos on online media — videos hidden by commercial social media ranking algorithms, which may usually only be seen by robots. Using face and image analysis algorithms to curate videos and study their subjects, ‘What the Robot Saw’ assembles its film and identifies its performers — as the Robot saw them.&nbsp;</p>

<p>Revealing a mix of underacknowledged media makers, performed selves, and obsessive surveillance algorithms, ‘What the Robot Saw’ enters into the complicated relationship between the world’s surveillant and curatorial AI robots and the humans who are both their subjects and their stars. It’s not a video about how robots actually see. It’s a response to processes of representation in the contemporary collision of performed selves, screen-centric perceptions — and robots.</p>

<p>Source:&nbsp;https://what-the-robot-saw.com</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>8581a668-2e39-40e0-a4f5-46dda9a54316</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>84f88848-a647-443c-b6ab-3bc16368977a</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>e6e09da9-caeb-4fd0-bd2f-ac24a2083283</target_uuid></field_themes><field_url><uri>https://what-the-robot-saw.com</uri><title></title><options/></field_url><field_year><value>2020-01-01</value></field_year></item><item key="4"><uuid><value>133c2eaf-f3c6-4a0f-940d-a46be2377dad</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2020-12-10T06:37:21+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>9253a06e-cca9-4065-ae8c-d4d2113dfee9</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>e061791f-08b7-4180-87aa-627c81734443</target_uuid></uid><title><value>(e)motion </value></title><created><value>2020-09-14T09:39:15+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2020-12-10T06:37:21+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/emotion</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>3818f7ae-3603-4a41-8b6c-91d9c8fe71d6</target_uuid></field_author_name><field_author_name><target_type>node</target_type><target_uuid>69796425-c02b-4679-82da-57e6074c86de</target_uuid></field_author_name><field_author_name><target_type>node</target_type><target_uuid>9090d57d-57ef-4246-ae13-caef3e78b9ca</target_uuid></field_author_name><field_characters/><field_country><value>DK</value></field_country><field_country><value>NL</value></field_country><field_country><value>DE</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>a92ac9e4-a36f-42c7-872c-4bed332792bc</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>4e8d1f8d-3f39-491e-a2ee-52f2570110bd</target_uuid></field_media_asset><field_multi_image><target_type>media</target_type><target_uuid>ba17706c-03ad-4b7f-92f2-ebd6fdec1af6</target_uuid></field_multi_image><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>460e8d77-8885-419b-ab02-4fa010a995a5</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>dd951d1c-96fd-4892-8ce6-0de1ad9f5d7a</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ff48d007-ea6a-441b-b998-138dab64c246</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>a73953c0-6ccf-499a-9d52-f9e485fcc469</target_uuid></field_sentiment><field_technologies_referenced/><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>a46eb94c-b7bd-41bb-855e-55bba9920c6d</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>As humans, we express what we think and feel by facial movements, often without even realizing it. In the&nbsp;<em>(e)motion</em>&nbsp;installation, the goal was to create awareness of even the subtlest movements of the face, and to facilitate interaction purely based on facial expressions. Facial movements were tracked by custom software and translated into motion vectors, which were in turn visualized and coupled with sounds. Participants could interact within the installation by responding to each other’s facial movements.&nbsp;<em>(e)motion</em>&nbsp;was inspired by embodied cognition and scientific studies on emotion and action. The installation was the result of an interdisciplinary collaboration between art, movement science and cognitive neuroscience.</p>

<p>Source:&nbsp;https://nordhjem.net/2018/02/01/faces-in-motion-embodiment-emotion-and-interaction/</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>affa508b-8e43-47ee-9add-ea87cc9f7eff</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>2d7e2ca0-db01-42cd-a8c8-5bcaf92a5417</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>ce0404a8-1d5b-43ee-a1c3-7444adbcc285</target_uuid></field_themes><field_url><uri>https://nordhjem.net/2018/02/01/faces-in-motion-embodiment-emotion-and-interaction/</uri><title></title><options/></field_url><field_year><value>2018-02-01</value></field_year></item><item key="5"><uuid><value>0236d61f-b4ae-44bc-961f-463cfb8cccc6</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-01-05T15:05:14+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>e061791f-08b7-4180-87aa-627c81734443</target_uuid></uid><title><value>(In)Security Camera</value></title><created><value>2020-11-12T09:50:51+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-01-05T15:05:14+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/insecurity-camera</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>f6597673-67d5-4931-a42a-bbafc2c226b0</target_uuid></field_author_name><field_author_name><target_type>node</target_type><target_uuid>55b4da84-a73a-41e3-85ca-24f37a9c3cfc</target_uuid></field_author_name><field_author_name><target_type>node</target_type><target_uuid>d6548151-57f7-44b0-b187-e9a92e442749</target_uuid></field_author_name><field_characters/><field_country><value>PE</value></field_country><field_country><value>US</value></field_country><field_country><value>RU</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>0b7ed1ad-e61a-4b0a-9883-6086adf855b4</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>a49a285e-8357-438f-9300-505682fd0fa9</target_uuid></field_media_asset><field_multi_image/><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>460e8d77-8885-419b-ab02-4fa010a995a5</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>f571f5e0-c59e-41b5-9190-dac45e982d22</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>47544283-06e1-437a-8bc4-12d5104e495f</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ecb9076e-8a09-4ca1-a615-e81b701acab4</target_uuid></field_sentiment><field_technologies_referenced/><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>dfd3c030-e860-4732-a4a7-786e433ffa88</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>da7f4c29-b985-4c3c-a912-f66e0bc5a2e4</target_uuid></field_technologies_used><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>c75f40e5-3fb7-4d4b-84b8-dc9c1f650d9d</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>The&nbsp;<em>(In)Security Camera</em>&nbsp;is a robotic surveillance camera with advanced computer-vision software that can track, zoom, and follow subjects walking through its field of view, assessing threat levels in real time and responding accordingly.</p>

<p>However, the camera is, in fact, a little insecure. Easily startled by sudden movements, it is shy around strangers and tends to avoid direct eye contact. The intention in creating the&nbsp;<em>(In)Security Camera</em>&nbsp;is to invert the relationship between the surveillance system and its subjects, giving the machine an element of human personality and fallibility that is by turns endearing, tragic, and slightly disturbing. This behavioral reversal can be read as an expression of the anxieties and fears underlying the security camera’s authoritative role; as an anti-voyeuristic refusal of visual pleasure; or as a kind of withdrawal, avoiding difficult questions and challenges.</p>

<p>Source:&nbsp;http://silviaruzanka.com/art/insecurity-camera/</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>e6e09da9-caeb-4fd0-bd2f-ac24a2083283</target_uuid></field_themes><field_url><uri>http://silviaruzanka.com/art/insecurity-camera/</uri><title></title><options/></field_url><field_year><value>2003-01-01</value></field_year></item><item key="6"><uuid><value>fd8cb52f-fd94-4994-8d83-25584925914e</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-11-11T12:37:27+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>446b9999-8a78-45c8-b558-c875d4aee362</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>6724b317-c0c6-4739-adc5-94cc8bc2049f</target_uuid></uid><title><value>... som duften av en dr&#xF8;m...</value></title><created><value>2020-11-04T12:16:44+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-11-11T12:37:27+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/som-duften-av-en-drom</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>da3db96d-2578-43d4-a0d6-d2d3182b36cb</target_uuid></field_author_name><field_characters><target_type>node</target_type><target_uuid>a812bb48-ca15-428a-9cb7-7e0549e76a44</target_uuid></field_characters><field_characters><target_type>node</target_type><target_uuid>6acd95b7-ae87-451c-bbce-debdcf94dd16</target_uuid></field_characters><field_characters><target_type>node</target_type><target_uuid>9bbde885-67cb-49d6-8e67-d355d8062b7a</target_uuid></field_characters><field_characters><target_type>node</target_type><target_uuid>be3c58c3-4fc2-48b5-9c8f-087eef25dcb4</target_uuid></field_characters><field_characters><target_type>node</target_type><target_uuid>351fe6cc-75b4-47cc-bd73-0c36fb2ac3ca</target_uuid></field_characters><field_country><value>NO</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>68ded8b5-a722-4cee-aa13-cb4947630af8</target_uuid></field_machine_vision_situation><field_machine_vision_situation><target_type>node</target_type><target_uuid>ad8e9c08-57d2-415b-b07e-d87033f76d8b</target_uuid></field_machine_vision_situation><field_machine_vision_situation><target_type>node</target_type><target_uuid>a94d77dd-2a12-4bec-9a9a-6fb7ae3ff0fe</target_uuid></field_machine_vision_situation><field_machine_vision_situation><target_type>node</target_type><target_uuid>35e74f7a-7f9c-4310-9b35-e6af081587e2</target_uuid></field_machine_vision_situation><field_machine_vision_situation><target_type>node</target_type><target_uuid>cfc0109a-1d81-4989-926a-7cb2ad44a305</target_uuid></field_machine_vision_situation><field_media_asset/><field_multi_image/><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>8bfaa6d9-607e-4628-92df-bc08840bd8c7</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>440a67c5-82be-4906-87dc-ffce1c1b6233</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>1</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>791bba71-1937-4481-8f9c-a8b4be6a48fd</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>e62fa1ca-3a49-45e7-bcb6-33a1ddc32723</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>f46689ea-6e96-491f-ade6-cc593884912a</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>fb5b6cf0-4881-4b16-a2c6-a9e8ff4ac20c</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>0c4573a5-3862-4bbb-bffb-3e29cac46d6e</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>c4c1372a-9ab3-46d9-8dcc-bbb8d551cee6</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>603ee9d6-8bfc-49f6-98e8-8b7514b05111</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>e3906ce1-7dd4-4b76-98d2-e86add14977e</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>b3adc0bc-b002-4235-87d1-97199c3cafdd</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>e4547afa-12e1-413c-906e-0d6a68ae8c7b</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>c75f40e5-3fb7-4d4b-84b8-dc9c1f650d9d</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>f1a66603-1cea-473d-8b79-a746d19f92cc</target_uuid></field_technologies_referenced><field_technologies_used/><field_textfield><value><![CDATA[<p>Ten short stories that show&nbsp;different people's relationship with technology. The book explores the future in a heavily digitalized Norway, and questions if humans will still be the same, or if the social and technological change will change human nature as a whole.&nbsp;</p>

<p>The book is logged as a novel rather than as separate short stories because the stories are interconnected, referencing the same technologies and social constructs and exploring the same possible future. Characters in some of the stories are also minor characters in other stories.</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>8581a668-2e39-40e0-a4f5-46dda9a54316</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>affa508b-8e43-47ee-9add-ea87cc9f7eff</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>72135a38-76ba-4f34-963a-bb92d05d9302</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>2d7e2ca0-db01-42cd-a8c8-5bcaf92a5417</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>6e49dfcc-c5c9-4288-bb1f-3146352e2158</target_uuid></field_themes><field_url/><field_year><value>2020-01-01</value></field_year></item><item key="7"><uuid><value>dfcf777b-dc1a-4ee3-9ed2-128d18e84e3c</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-03-26T10:44:39+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></uid><title><value>10.000 Moving Cities &#x2013; Same but Different, VR</value></title><created><value>2019-03-27T14:47:37+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-03-26T10:44:39+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/10000-moving-cities-same-different-vr</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>c1bc6a5c-c53c-4bbb-a6ae-ac805548a7ce</target_uuid></field_author_name><field_characters/><field_country><value>CH</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>ccbecd4c-9d26-4bba-9318-5556766a5201</target_uuid></field_machine_vision_situation><field_media_asset/><field_multi_image/><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>460e8d77-8885-419b-ab02-4fa010a995a5</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>21789815-9286-4c11-bdb1-f9921745b2af</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>fb5b6cf0-4881-4b16-a2c6-a9e8ff4ac20c</target_uuid></field_sentiment><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>7ccfa6b2-a380-465b-9711-7697bade8f7d</target_uuid></field_technologies_referenced><field_technologies_referenced><target_type>taxonomy_term</target_type><target_uuid>1214ed40-5e6c-4612-9337-298f01f798a5</target_uuid></field_technologies_referenced><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>f1a66603-1cea-473d-8b79-a746d19f92cc</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p><cite>10.000 Moving Cities – Same but Different</cite> deals with urbanization and globalization in the digital age. The user moves through visual worlds posted publicly by others on social networks such as YouTube, Flickr or Twitter. Here these personal impressions are streamed in real time like windows to our changing world. The viewer participates in the social movements of our time and makes a virtual journey into constantly new image and sound collages in which one experiences local, cultural and linguistic differences and similarities. In virtual space, this information is visualized on cubes that rise at different heights to become a kind of skyline. The work deals with how our cities are continuously changing and increasingly resemble one. This results in more and more non-places/places of lost places in the sense of Marc Augé’s book and essay Non-Places, which could exist all over the world without any true local identity (mostly anonymous transition zones such as motorways, hotel rooms or airports).</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>2ff31a16-a301-44bd-8201-339a065d0864</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>84f88848-a647-443c-b6ab-3bc16368977a</target_uuid></field_themes><field_url><uri>http://marclee.io/en/10-000-moving-cities-same-but-different-vr/</uri><title></title><options/></field_url><field_year><value>2016-01-01</value></field_year></item><item key="8"><uuid><value>48089ed2-dc88-41f4-9540-f1187f1a131c</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2020-12-02T09:43:53+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>9253a06e-cca9-4065-ae8c-d4d2113dfee9</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>e061791f-08b7-4180-87aa-627c81734443</target_uuid></uid><title><value>15 minutes of biometric fame</value></title><created><value>2020-09-15T08:24:36+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2020-12-02T09:43:53+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/15-minutes-biometric-fame</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>dd653423-2abe-434b-8961-536bafd6f05d</target_uuid></field_author_name><field_characters/><field_country><value>NL</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>cf2106d5-2c5f-42b9-9166-01557024443e</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>98a26df6-bde1-48c2-b9bb-0eb1f10db931</target_uuid></field_media_asset><field_multi_image><target_type>media</target_type><target_uuid>a3ac7455-133a-4d94-b76f-1ddafda48228</target_uuid></field_multi_image><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>460e8d77-8885-419b-ab02-4fa010a995a5</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>9ac94332-f441-49ad-9fc8-4b4b09fc5779</target_uuid></field_record_status><field_science_fiction><value>1</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>47544283-06e1-437a-8bc4-12d5104e495f</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>e62fa1ca-3a49-45e7-bcb6-33a1ddc32723</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ecb9076e-8a09-4ca1-a615-e81b701acab4</target_uuid></field_sentiment><field_technologies_referenced/><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>62833fd3-3e21-4d62-840a-7333cc0cdbc7</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>15 Minutes of Biometric Fame not only highlights paradoxes associated with celebrity recognition within the entertainment industry and instant fame received through various Web 2.0 applications, but it playfully discredits the reliability of internet data bases by diffusing everyday individuals with ambiguous tagging back into the system.</p>

<p>Like&nbsp;<a href="http://www.marnixdenijs.nl/physiognomic_scrutinizer.php">Physiognomic Scrutinizer</a>&nbsp;(2008 – 2009) and&nbsp;<a href="http://www.marnixdenijs.nl/mirror_piece.php">Mirror_Piece</a>&nbsp;(2010 – 2011), 15 Minutes of Biometric Fame also incorporates face-recognition software employed in surveillance and security applications. In contrast, the design draws inspiration from camera dollies utilised in television and cinematography.</p>

<p>A circular track is fitted with a camera crane mounted with an independently operated camera. The camera lens imposes on public space, seeking out and scanning the visitor’s facial features. Rather than identifying a person, the biometric video analysis software assists in comparing their characteristics with a preselected data base of “celebrity” faces.</p>

<p>Compiled by De Nijs from a series of multilingual online search results, the initial 75,000 strong data bank consisted of typical celebrity personages as well as those who have attained fame through exposure on reality television and from the world of internet video. Each individual is tagged with one of twelve categories of stardom in one of eleven languages. These can range from artist to rock or porn star through to soap actor and musician.</p>

<p>Attached to the camera, an LCD monitor displays this matching process and those visitors who can be partnered as lookalikes to a data base celebrity are then projected on a large public screen. Not only are they similarly tagged but they are further identifiable with a generation label. A direct match with an original celebrity earns a 2nd generation tag. It follows that a comparison with subsequent generation levels moves you further down the lineage. This "ancestry of fame" is also displayed in its entirety.</p>

<p>Once a visitor is captured, matched and tagged, they are subsequently added to the continually expanding data base, uploaded to the internet and hence promoted to instant stardom. In this way, 15 Minutes of Biometric Fame is not only critiquing the act of “becoming famous”, but the precursor conditions for celebrity credibility as well.</p>

<p>Source:&nbsp;http://www.marnixdenijs.nl/15-minutes-of-biometric-fame.htm</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>8581a668-2e39-40e0-a4f5-46dda9a54316</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>2d7e2ca0-db01-42cd-a8c8-5bcaf92a5417</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>ce0404a8-1d5b-43ee-a1c3-7444adbcc285</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>84f88848-a647-443c-b6ab-3bc16368977a</target_uuid></field_themes><field_url><uri>http://www.marnixdenijs.nl/15-minutes-of-biometric-fame.htm</uri><title></title><options/></field_url><field_year><value>2011-01-01</value></field_year></item><item key="9"><uuid><value>a018a7b1-265e-4032-84b1-e196ecc8a2fd</value></uuid><langcode><value>en</value></langcode><type><target_id>work</target_id><target_type>node_type</target_type><target_uuid>cf1e412e-90c1-4fc6-b392-937147c09c52</target_uuid></type><revision_timestamp><value>2021-11-26T10:29:12+00:00</value><format>Y-m-d\TH:i:sP</format></revision_timestamp><revision_uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></revision_uid><revision_log/><status><value>1</value></status><uid><target_type>user</target_type><target_uuid>5ebc1a24-0c2e-4292-afa4-3ef37d024a03</target_uuid></uid><title><value>17 Cities</value></title><created><value>2020-10-19T09:25:02+00:00</value><format>Y-m-d\TH:i:sP</format></created><changed><value>2021-11-26T10:29:12+00:00</value><format>Y-m-d\TH:i:sP</format></changed><promote><value>0</value></promote><sticky><value>0</value></sticky><default_langcode><value>1</value></default_langcode><revision_translation_affected><value>1</value></revision_translation_affected><path><alias>/creative-work/17-cities</alias><langcode>en</langcode><pathauto>1</pathauto></path><field_author_name><target_type>node</target_type><target_uuid>6b8628a9-564a-4b40-8dfc-c0833a8fe127</target_uuid></field_author_name><field_characters/><field_country><value>CA</value></field_country><field_country><value>NL</value></field_country><field_country><value>DE</value></field_country><field_machine_vision_situation><target_type>node</target_type><target_uuid>72830d99-cf4c-4160-b546-d6bf33d0e3c4</target_uuid></field_machine_vision_situation><field_media_asset><target_type>media</target_type><target_uuid>da09d2f5-b4a1-415a-aa26-d179b254e678</target_uuid></field_media_asset><field_multi_image><target_type>media</target_type><target_uuid>94b62aa7-4f58-42dc-8760-b50789c694dc</target_uuid></field_multi_image><field_notes/><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>bc0b9dfe-a08b-457e-9c28-3e3047259709</target_uuid></field_publication_type><field_publication_type><target_type>taxonomy_term</target_type><target_uuid>830da266-5d27-4788-9ca4-48397bb5319f</target_uuid></field_publication_type><field_pullquote/><field_record_status><target_type>taxonomy_term</target_type><target_uuid>21789815-9286-4c11-bdb1-f9921745b2af</target_uuid></field_record_status><field_science_fiction><value>0</value></field_science_fiction><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>6edd417a-fd7f-4332-82ef-6286b1375f06</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>ff48d007-ea6a-441b-b998-138dab64c246</target_uuid></field_sentiment><field_sentiment><target_type>taxonomy_term</target_type><target_uuid>e62fa1ca-3a49-45e7-bcb6-33a1ddc32723</target_uuid></field_sentiment><field_technologies_referenced/><field_technologies_used><target_type>taxonomy_term</target_type><target_uuid>c75f40e5-3fb7-4d4b-84b8-dc9c1f650d9d</target_uuid></field_technologies_used><field_textfield><value><![CDATA[<p>A compilation of video generated during a series of walks through various cities, 17 in total, from 2003-2008.&nbsp;</p>

<p>&nbsp;Wireless surveillance video, transmitting from offices, streets, stores and homes, was intercepted walking through different city streets while carrying a commercial model video scanner.&nbsp;</p>

<p>&nbsp;An animated selection from this archive, separated over three screens, cycles through scenes from Brussels, Berlin, Chicago, Seoul, Barcelona, Montreal, and other cities throughout Europe and North America. Moving from the commercial space to the street, to the home, the bed, to the televisual (television wirelessly distributed between rooms in homes can also be intercepted), and finally moving back out into the urban nightlife, parallel stories start appear, and cities start to merge into a meta-narrative of contemporary urbanity as depicted through the eyes of the surveillance camera.</p>

<p>Source: http://www.ubermatic.lftk.org/blog/?p=203</p>
]]></value><format>basic_text_editor</format></field_textfield><field_themes><target_type>taxonomy_term</target_type><target_uuid>e8dab263-5453-4aa9-a3bd-7f51e393d623</target_uuid></field_themes><field_themes><target_type>taxonomy_term</target_type><target_uuid>e6e09da9-caeb-4fd0-bd2f-ac24a2083283</target_uuid></field_themes><field_url><uri>http://www.ubermatic.lftk.org/blog/?p=203</uri><title></title><options/></field_url><field_year><value>2008-01-01</value></field_year></item></response>
